{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9404e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f82e9a",
   "metadata": {},
   "source": [
    "# Vocabulary Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d79cc",
   "metadata": {},
   "source": [
    "The first task is to create a vocabulary using the training data. In HMM, one important problem when creating the vocabulary is to handle unknown words. One simple solution is to replace rare words whose occurrences are less than a threshold (e.g. 3) with a special token ‘< unk >’."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30f850",
   "metadata": {},
   "source": [
    "- Used pandas read_csv method to read the train, dev and test dataset into a pandas dataframe using tab separator.\n",
    "- pandas.DataFrame.head method returns the first n rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dd7f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>old</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>join</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  pos\n",
       "0      1  Pierre  NNP\n",
       "1      2  Vinken  NNP\n",
       "2      3       ,    ,\n",
       "3      4      61   CD\n",
       "4      5   years  NNS\n",
       "5      6     old   JJ\n",
       "6      7       ,    ,\n",
       "7      8    will   MD\n",
       "8      9    join   VB\n",
       "9     10     the   DT"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train', sep = '\\t', header = None, names = ['index','word','pos'])\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05e8b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Corporations</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Commission</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>authorized</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>%</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>rate</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>increase</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          word  pos\n",
       "0      1           The   DT\n",
       "1      2       Arizona  NNP\n",
       "2      3  Corporations  NNP\n",
       "3      4    Commission  NNP\n",
       "4      5    authorized  VBD\n",
       "5      6            an   DT\n",
       "6      7          11.5   CD\n",
       "7      8             %   NN\n",
       "8      9          rate   NN\n",
       "9     10      increase   NN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv('data/dev', sep = '\\t', header = None, names = ['index','word','pos'])\n",
    "dev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de01b1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Influential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>introduced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         word\n",
       "0      1  Influential\n",
       "1      2      members\n",
       "2      3           of\n",
       "3      4          the\n",
       "4      5        House\n",
       "5      6         Ways\n",
       "6      7          and\n",
       "7      8        Means\n",
       "8      9    Committee\n",
       "9     10   introduced"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test',sep='\\t',header=None,names=['index','word'])\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62001247",
   "metadata": {},
   "source": [
    "## What is the selected threshold for unknown words replacement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cad200",
   "metadata": {},
   "source": [
    "- I set the threshold to 2 to replace words having frequency less than threshold with the < unk > token.\n",
    "- Used Counter class to get the frequency of all words in the training set and converted Counter object to dictionary.\n",
    "- Replaced all the rarely occuring words with < unk > token and updated count of < unk > token in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961e0214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 2\n",
    "word_list = train['word'].tolist()\n",
    "word_counter = Counter(word_list)\n",
    "vocabulary_dict = dict(word_counter)\n",
    "temp_dict = dict(word_counter)\n",
    "for word in temp_dict:\n",
    "    if(vocabulary_dict[word] < THRESHOLD):\n",
    "        if('<unk>' not in vocabulary_dict):\n",
    "            vocabulary_dict['<unk>'] = 0\n",
    "        vocabulary_dict['<unk>'] += vocabulary_dict[word]\n",
    "        del vocabulary_dict[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fb294",
   "metadata": {},
   "source": [
    "## What is the total size of your vocabulary and what is the total occurrences of the special token ‘< unk >’ after replacement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf11900",
   "metadata": {},
   "source": [
    "- There are 23183 unique words in the vocabulary including the < unk > token.\n",
    "- There are 20011 occurences of < unk > token in the data after replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874ea9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23183"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3610816c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20011"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_dict['<unk>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2a6e7",
   "metadata": {},
   "source": [
    "## Created a vocabulary using the training data in the file train and outputted the vocabulary into a txt file named vocab.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6854c1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(46476, ','),\n",
       " (39533, 'the'),\n",
       " (37452, '.'),\n",
       " (22104, 'of'),\n",
       " (21305, 'to'),\n",
       " (18469, 'a'),\n",
       " (15346, 'and'),\n",
       " (14609, 'in'),\n",
       " (8872, \"'s\"),\n",
       " (7743, 'for')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = []\n",
    "unk_count = vocabulary_dict['<unk>']\n",
    "del vocabulary_dict['<unk>']\n",
    "for word in vocabulary_dict:\n",
    "    vocab_list.append((vocabulary_dict[word],word))\n",
    "vocab_list.sort(reverse = True)\n",
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1025a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.txt','w') as file:\n",
    "    lines = ['<unk>\\t0\\t'+ str(unk_count)+'\\n']\n",
    "    idx = 1\n",
    "    for each in vocab_list:\n",
    "        line = each[1] + '\\t' + str(idx) + '\\t' + str(each[0])+'\\n'\n",
    "        lines.append(line)\n",
    "        idx += 1\n",
    "    file.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f63c6a",
   "metadata": {},
   "source": [
    "# Model Learning - HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed2c5d",
   "metadata": {},
   "source": [
    "The second task is to learn an HMM from the training data. Remember that the solution of the emission and transition parameters in HMM are in the following formulation:<br>\n",
    "t(s0|s) = count(s→s0)/count(s)<br>\n",
    "e(x|s) = count(s→x)/count(s)<br>\n",
    "where t(·|·) is the transition parameter and e(·|·) is the emission parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03614d68",
   "metadata": {},
   "source": [
    "- Created a dictionary from a Counter object having tag names and corresponding frequency of the tag in the training data.\n",
    "- This dictionary gives us the count(s) term in the above formulaes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6f5ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning HMM Probabilities...\n"
     ]
    }
   ],
   "source": [
    "print('Learning HMM Probabilities...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4655e6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NNP', 87608),\n",
       " (',', 46480),\n",
       " ('CD', 34876),\n",
       " ('NNS', 57859),\n",
       " ('JJ', 58944),\n",
       " ('MD', 9437),\n",
       " ('VB', 25489),\n",
       " ('DT', 78775),\n",
       " ('NN', 127534),\n",
       " ('IN', 94758)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counter = Counter(train['pos'])\n",
    "tag_dict = dict(tag_counter)\n",
    "list(tag_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f0374",
   "metadata": {},
   "source": [
    "- The next code block is equivalent to creating a beginning of sentence tag at the start of each sentence.\n",
    "- The code counts the number of times each tag appears as the first tag in a sentence and divides it by the number of sentences, thus, giving us the probability of the tag occuring at the start of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf4ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tag_probs = {}\n",
    "count_first_tag = {}\n",
    "for tag in train[train['index']==1]['pos'].tolist():\n",
    "    if tag not in count_first_tag:\n",
    "        count_first_tag[tag] = 0\n",
    "    count_first_tag[tag] += 1\n",
    "\n",
    "for key in count_first_tag:\n",
    "    first_tag_probs[key] = count_first_tag[key]/len(train[train['index']==1]['pos'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb428e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NNP', 0.19789104610393007),\n",
       " ('DT', 0.21911141347009264),\n",
       " ('IN', 0.1288398137003506),\n",
       " ('PRP', 0.06148935056779528),\n",
       " ('EX', 0.004238840337013972),\n",
       " ('``', 0.07472918520069077),\n",
       " ('CD', 0.011225077188759224),\n",
       " ('RBR', 0.0020932544874143074),\n",
       " ('NNS', 0.041237113402061855),\n",
       " ('NN', 0.0411847820398765)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(first_tag_probs.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550f9cc",
   "metadata": {},
   "source": [
    "- Creating a list of list 'sentences' containing each sentence of the training set inside a separate list, where all words of the sentence which are not found in the vocabulary are replaced by < unk > token.\n",
    "- Also, created a similar list of lists 'sentence_tags' which contains the corresponding tags in similar structure.\n",
    "- Repeated this process for train, dev and test (no sentence_tags in test) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faaca9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence_tags = []\n",
    "tags = []\n",
    "sentence = None\n",
    "for row in train.values.tolist():\n",
    "    if row[0] == 1:\n",
    "        if sentence:\n",
    "            sentence_tags.append(tags)\n",
    "            sentences.append(sentence)\n",
    "        sentence = []\n",
    "        tags = []\n",
    "    if row[1] not in vocabulary_dict:\n",
    "        sentence.append('<unk>')\n",
    "    else:\n",
    "        sentence.append(row[1])\n",
    "    tags.append(row[2])\n",
    "sentence_tags.append(tags)\n",
    "sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fcc866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierre',\n",
       "  'Vinken',\n",
       "  ',',\n",
       "  '61',\n",
       "  'years',\n",
       "  'old',\n",
       "  ',',\n",
       "  'will',\n",
       "  'join',\n",
       "  'the',\n",
       "  'board',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'Nov.',\n",
       "  '29',\n",
       "  '.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d27503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NNP',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'CD',\n",
       "  'NNS',\n",
       "  'JJ',\n",
       "  ',',\n",
       "  'MD',\n",
       "  'VB',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'NNP',\n",
       "  'CD',\n",
       "  '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tags[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf9e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = []\n",
    "dev_sentence_tags = []\n",
    "tags = []\n",
    "sentence = None\n",
    "for row in dev.values.tolist():\n",
    "    if row[0] == 1:\n",
    "        if sentence:\n",
    "            dev_sentence_tags.append(tags)\n",
    "            dev_sentences.append(sentence)\n",
    "        sentence = []\n",
    "        tags = []\n",
    "    if row[1] not in vocabulary_dict:\n",
    "        sentence.append('<unk>')\n",
    "    else:\n",
    "        sentence.append(row[1])\n",
    "    tags.append(row[2])\n",
    "dev_sentence_tags.append(tags)\n",
    "dev_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f0df71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "sentence = None\n",
    "for row in test.values.tolist():\n",
    "    if row[0] == 1:\n",
    "        if sentence:\n",
    "            test_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    if row[1] not in vocabulary_dict:\n",
    "        sentence.append('<unk>')\n",
    "    else:\n",
    "        sentence.append(row[1])\n",
    "test_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be40df",
   "metadata": {},
   "source": [
    "- Created function create_bigram_dict to compute the count of s->s' using training data variable 'sentence_tags', returns a dictionary with key structured as a tuple (s,s') where s is the tag and s' is the next tag in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fff12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_dict(sentences):\n",
    "    bigram_dict = {}\n",
    "    for sentence in sentences:\n",
    "        for idx, word in enumerate(sentence[:-1]):\n",
    "            key = (word, sentence[idx+1])\n",
    "            if key not in bigram_dict:\n",
    "                bigram_dict[key] = 0\n",
    "            bigram_dict[key]+=1\n",
    "    return bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1500a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tag_dict = create_bigram_dict(sentence_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c70f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NNP', 'NNP'), 33139),\n",
       " (('NNP', ','), 12131),\n",
       " ((',', 'CD'), 987),\n",
       " (('CD', 'NNS'), 5502),\n",
       " (('NNS', 'JJ'), 995),\n",
       " (('JJ', ','), 1717),\n",
       " ((',', 'MD'), 490),\n",
       " (('MD', 'VB'), 7541),\n",
       " (('VB', 'DT'), 5661),\n",
       " (('DT', 'NN'), 37299)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram_tag_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727bde0",
   "metadata": {},
   "source": [
    "- Calculated the transition probabilities using the bigram_tag_dict and tag_dict created above. The resulting dictionary contains keys similar to bigram_tag_dict i.e., in tuple format (s,s') with the corresponding transition probability as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b5cd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {}\n",
    "for key in bigram_tag_dict:\n",
    "    transition_probs[key] = (bigram_tag_dict[key])/(tag_dict[key[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbf254d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NNP', 'NNP'), 0.3782645420509543),\n",
       " (('NNP', ','), 0.13846908958086018),\n",
       " ((',', 'CD'), 0.021234939759036144),\n",
       " (('CD', 'NNS'), 0.15775891730703062),\n",
       " (('NNS', 'JJ'), 0.017196978862406887),\n",
       " (('JJ', ','), 0.029129343105320303),\n",
       " ((',', 'MD'), 0.010542168674698794),\n",
       " (('MD', 'VB'), 0.7990886934407121),\n",
       " (('VB', 'DT'), 0.22209580603397544),\n",
       " (('DT', 'NN'), 0.4734877816566169)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(transition_probs.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11371e45",
   "metadata": {},
   "source": [
    "- Created tag_word_dict, a dictionary with key structured as a tuple (s,x), which contains the count of s->x using training data variables 'sentences' and 'sentence_tags' where s is the tag and x is the corresponding word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837b3d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NNP', 'Pierre'), 6),\n",
       " (('NNP', 'Vinken'), 2),\n",
       " ((',', ','), 46476),\n",
       " (('CD', '61'), 25),\n",
       " (('NNS', 'years'), 1130),\n",
       " (('JJ', 'old'), 213),\n",
       " (('MD', 'will'), 2962),\n",
       " (('VB', 'join'), 40),\n",
       " (('DT', 'the'), 39517),\n",
       " (('NN', 'board'), 297)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_word_dict = {}\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences[i])):\n",
    "        key = (sentence_tags[i][j], sentences[i][j])\n",
    "        if key not in tag_word_dict:\n",
    "            tag_word_dict[key] = 0\n",
    "        tag_word_dict[key]+=1\n",
    "list(tag_word_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d3c6e",
   "metadata": {},
   "source": [
    "- Calculated the emission probabilities using the tag_word_dict and tag_dict created above. The resulting dictionary contains keys similar to tag_word_dict i.e., in tuple format (s,x) with the corresponding emission probability as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da525345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NNP', 'Pierre'), 6.84868961738654e-05),\n",
       " (('NNP', 'Vinken'), 2.2828965391288468e-05),\n",
       " ((',', ','), 0.9999139414802065),\n",
       " (('CD', '61'), 0.0007168253240050465),\n",
       " (('NNS', 'years'), 0.019530237301024905),\n",
       " (('JJ', 'old'), 0.003613599348534202),\n",
       " (('MD', 'will'), 0.3138709335593939),\n",
       " (('VB', 'join'), 0.0015693044058221193),\n",
       " (('DT', 'the'), 0.5016439225642653),\n",
       " (('NN', 'board'), 0.0023287907538381922)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probs = {}\n",
    "for key in tag_word_dict:\n",
    "    emission_probs[key] = (tag_word_dict[key])/(tag_dict[key[0]])\n",
    "list(emission_probs.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344f31f",
   "metadata": {},
   "source": [
    "- Created dictionary hmm_dict which consists of key 'transition' with the 'transition_probs' dictionary as value, and key 'emission' with the 'emission_probs' dictionary as value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "142cc7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmm_dict = {}\n",
    "hmm_dict['transition'] = transition_probs\n",
    "hmm_dict['emission'] = emission_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feae0a3",
   "metadata": {},
   "source": [
    "- Since json files cannot accept tuple as keys, created a copy of hmm_dict with keys of transition and emission probabilities as strings instead of tuples with elements of tuple separated by a |. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e515cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_dict_copy = {'transition':{},'emission':{}}\n",
    "for key in hmm_dict:\n",
    "    for pair in hmm_dict[key]:\n",
    "        hmm_dict_copy[key][pair[0]+'|'+pair[1]] = hmm_dict[key][pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bbda2",
   "metadata": {},
   "source": [
    "- Wrote the hmm_dict_copy dictionary to hmm.json as asked by the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25058ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hmm.json','w+') as file:\n",
    "    json.dump(hmm_dict_copy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a44d4",
   "metadata": {},
   "source": [
    "## How many transition and emission parameters in your HMM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06481030",
   "metadata": {},
   "source": [
    "- There are 1351 transition parameters in the transition probabilities dictionary.\n",
    "- There are 30303 emission parameters in the emission probabilities dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44fcdb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transition_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ec22d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30303"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emission_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70b6b0",
   "metadata": {},
   "source": [
    "# Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de7fe5",
   "metadata": {},
   "source": [
    "The third task is to implement the greedy decoding algorithm with HMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfdb2a",
   "metadata": {},
   "source": [
    "- Created a word-wise dictionary containing each word from vocabulary as key and value as a dictionary containing only the emission probabilities for that word.\n",
    "- This is done to make greedy decoding run faster by iterating over only the corresponding emissions of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31da96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CC', 'and'): 0.6722180830082833,\n",
       " ('JJ', 'and'): 5.0895765472312706e-05,\n",
       " ('IN', 'and'): 1.0553198674518247e-05,\n",
       " ('NN', 'and'): 1.5682092618439004e-05,\n",
       " ('NNP', 'and'): 2.2828965391288468e-05}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probs_2 = {}\n",
    "\n",
    "for key in emission_probs:\n",
    "    if key[1] not in emission_probs_2:\n",
    "        emission_probs_2[key[1]] = {}\n",
    "    emission_probs_2[key[1]][key]= emission_probs[key]\n",
    "emission_probs_2['and']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae368f2",
   "metadata": {},
   "source": [
    "- Created function greedy_decode which takes a list of words as input (the words are strictly from the vocabulary otherwise < unk >).\n",
    "- This function iterates over the words in the input sentence. If it is the first word, the emission probability for each (tag,word) pair in 'emission_probs_2[word]' is multiplied with probability of the tag being the first tag by using 'first_tag_probs' dictionary.\n",
    "- If the word is not the first word, then, we calculate probability as the multiplication of the emission probability for each (tag,word) pair in 'emission_probs_2[word]' and the transition probability of the corresponding tag given the previous tag.\n",
    "- At each iteration, we save the tag having the maximum probability and move to the next word. Hence this approach is greedy in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88507de9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def greedy_decode(sentence):\n",
    "    max_keys = []\n",
    "    for i,word in enumerate(sentence):\n",
    "        max_prob = 0\n",
    "        max_key = None\n",
    "        if i == 0:\n",
    "            for key in emission_probs_2[word]:\n",
    "                em_prob = emission_probs_2[word][key]\n",
    "                ft_prob = first_tag_probs.get(key[0],0)\n",
    "                if em_prob*ft_prob >= max_prob:\n",
    "                    max_prob = em_prob*ft_prob\n",
    "                    max_key = key\n",
    "        else:\n",
    "            for key in emission_probs_2[word]:\n",
    "                prev_emission = max_keys[-1][0]\n",
    "                transition = (prev_emission,key[0])\n",
    "                tr_prob = transition_probs.get(transition,0)\n",
    "                total_prob = tr_prob * emission_probs_2[word][key]\n",
    "                if total_prob >= max_prob:\n",
    "                    max_prob = total_prob\n",
    "                    max_key = key\n",
    "        max_keys.append(max_key)\n",
    "    return [x[0] for x in max_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818ec00",
   "metadata": {},
   "source": [
    "## What is the accuracy of greedy decoding on the dev data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1d36d",
   "metadata": {},
   "source": [
    "The computed accuracy on the development data for my model comes out to be 93.516% as computed in Part 5 (Accuracy Computation) of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598152ab",
   "metadata": {},
   "source": [
    "# Viterbi Decoding with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c535c",
   "metadata": {},
   "source": [
    "- Created function 'make_log_probs' which takes a dictionary as input and converts all the probability values in the dictionary to log probabilities and outputs it as a dictionary with the same keys but values as log probabilities.\n",
    "- Used this function to create log probabilities dictionaries for transition, emission and first-tag probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85ecc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_probs(probs):\n",
    "    return {key:np.log(probs[key]) for key in probs}\n",
    "    \n",
    "transition_log_probs = make_log_probs(transition_probs)\n",
    "emission_log_probs = make_log_probs(emission_probs)\n",
    "first_tag_log_probs = make_log_probs(first_tag_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc81b2",
   "metadata": {},
   "source": [
    "- Created a function 'viterbi_decode' which takes list of words as input and performs viterbi decoding using log of transition, emission and first-tag probabilities created above.\n",
    "- Viterbi algorithm is a dynamic programming algorithm which returns an optimal sequence of tags for words of a given sentence.\n",
    "- In this algorithm, we use a optimal substructure 'V' which stores a word-wise list of dictionaries with each dictionary having all possible tags in the dataset as keys and value as another dictionary having the probability of that tag and the name of the previous tag in the sequence being computed.\n",
    "- For the first word, first tag and emission log probabilities are used to obtain probability of the tag with previous tag as None.\n",
    "- For all other words, the log probability value of stored for all tags of previous word in V along with the transition and emission log probabilities are used to get probability of the tag for the current word and stored at corresponding position in V.\n",
    "- Once V is calculated, we backtrack from the tag of the last word which has the maximum log probability, till the first tag using the previous tag key called 'prev' in V.\n",
    "- The above algorithm gives a very small probability (log probability = -1000) to keys which are not found in the transition, emission and first-tag log probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf4c2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(sentence):\n",
    "    tags = list(tag_dict.keys())\n",
    "    \n",
    "    K = len(tags)\n",
    "    T = len(sentence)\n",
    "    V = [{}]\n",
    "    \n",
    "    for tag in tags:\n",
    "        if sentence[0] != '<unk>':\n",
    "            V[0][tag] = {\"prob\":first_tag_log_probs.get(tag,-1000)+emission_log_probs.get((tag,sentence[0]),-1000),\n",
    "                   \"prev\" : None}\n",
    "        else:\n",
    "            V[0][tag] = {\"prob\":first_tag_log_probs.get(tag,-1000),\"prev\" : None}\n",
    "        \n",
    "    for i in range(1,T):\n",
    "        V.append({})\n",
    "        for tag in tags:\n",
    "            if sentence[i] != '<unk>':\n",
    "                max_tr_prob = V[i - 1][tags[0]][\"prob\"] + transition_log_probs.get((tags[0],tag),-1000)  + emission_log_probs.get((tag,sentence[i]),-1000)\n",
    "            else:\n",
    "                max_tr_prob = V[i - 1][tags[0]][\"prob\"] + transition_log_probs.get((tags[0],tag),-1000)\n",
    "            prev_st_selected = tags[0]\n",
    "            for prev_st in tags[1:]:\n",
    "                tr_prob = V[i-1][prev_st]['prob'] + transition_log_probs.get((prev_st,tag),-1000) + emission_log_probs.get((tag,sentence[i]),-1000)\n",
    "                if tr_prob > max_tr_prob:\n",
    "                    max_tr_prob = tr_prob\n",
    "                    prev_st_selected = prev_st\n",
    "            \n",
    "            max_prob = max_tr_prob\n",
    "            V[i][tag] = {\"prob\":max_prob,\"prev\":prev_st_selected}\n",
    "    \n",
    "    opt = []\n",
    "    max_prob = float('-inf')\n",
    "    best_tag = None\n",
    "    for tag, data in V[-1].items():\n",
    "        if data['prob'] > max_prob:\n",
    "            max_prob = data['prob']\n",
    "            best_tag = tag\n",
    "    opt.append(best_tag)\n",
    "    previous = best_tag\n",
    "        \n",
    "    for i in range(len(V)-2,-1,-1):\n",
    "        opt.insert(0,V[i+1][previous]['prev'])\n",
    "        previous = V[i + 1][previous][\"prev\"]\n",
    "    \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332479c3",
   "metadata": {},
   "source": [
    "## What is the accuracy of viterbi decoding on the dev data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d33a02",
   "metadata": {},
   "source": [
    "The computed accuracy on the development data for my model comes out to be 94.634% as computed in Part 5 (Accuracy Computation) of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2660594e",
   "metadata": {},
   "source": [
    "# Accuracy Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d65240",
   "metadata": {},
   "source": [
    "- Created function compute_accuracy which computes the accuracy for both greedy and viterbi decoding. \n",
    "- It counts the number of tags that the decoder predicted correctly in the entire given dataset and divides it by the total number of tags in the entire given dataset and prints the values in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb21bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(sentences,sentence_tags):\n",
    "    greedy_count = 0\n",
    "    viterbi_count = 0\n",
    "    actual_count = 0\n",
    "    \n",
    "    for i,sentence in enumerate(sentences):\n",
    "        greedy_tags = np.array(greedy_decode(sentence))\n",
    "        viterbi_tags = np.array(viterbi_decode(sentence))\n",
    "        actual_tags = np.array(sentence_tags[i])\n",
    "        greedy_count += np.sum(greedy_tags==actual_tags)\n",
    "        viterbi_count += np.sum(viterbi_tags==actual_tags)\n",
    "        actual_count += len(sentence_tags[i])\n",
    "        \n",
    "    greedy_acc = greedy_count/actual_count\n",
    "    viterbi_acc = viterbi_count/actual_count\n",
    "    \n",
    "    print('Accuracy for Greedy Decoding: '+str(greedy_acc*100)+\"%\\nAccuracy for Viterbi Decoding: \"+str(viterbi_acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a47e89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Accuracy on dev...\n",
      "Accuracy for Greedy Decoding: 93.51587638880457%\n",
      "Accuracy for Viterbi Decoding: 94.63375022767288%\n"
     ]
    }
   ],
   "source": [
    "print('Computing Accuracy on dev...')\n",
    "compute_accuracy(dev_sentences,dev_sentence_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ea873",
   "metadata": {},
   "source": [
    "# Testing on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f637731",
   "metadata": {},
   "source": [
    "Predicting the part-of-speech tags of the sentences in the test data and output the predictions in files named greedy.out (for greedy decoder) and viterbi.out (for viterbi decoder), in the same format of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f426ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing tags on test data...\n"
     ]
    }
   ],
   "source": [
    "print('Computing tags on test data...')\n",
    "predicted_test_greedy_tags = []\n",
    "predicted_test_viterbi_tags = []\n",
    "for sentence in test_sentences:\n",
    "    predicted_test_greedy_tags += greedy_decode(sentence)\n",
    "    predicted_test_viterbi_tags += viterbi_decode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40147bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['greedy_tags'] = predicted_test_greedy_tags\n",
    "test['viterbi_tags'] = predicted_test_viterbi_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2e7f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('greedy.out','w+') as f:\n",
    "    test_list = test[['index','word','greedy_tags']].values.astype(str).tolist()\n",
    "    lines = ['\\t'.join(x)+'\\n' for x in test_list]\n",
    "    for i,line in enumerate(lines):\n",
    "        if line[:2] == '1\\t' and i!=0:\n",
    "            f.write('\\n')\n",
    "        f.write(line)\n",
    "    \n",
    "with open('viterbi.out','w+') as f:\n",
    "    test_list = test[['index','word','viterbi_tags']].values.astype(str).tolist()\n",
    "    lines = ['\\t'.join(x)+'\\n' for x in test_list]\n",
    "    for i,line in enumerate(lines):\n",
    "        if line[:2] == '1\\t' and i!=0:\n",
    "            f.write('\\n')\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60b2bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a3765",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://en.wikipedia.org/wiki/Viterbi_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33811ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
